{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'antislop-sampler'...\n",
      "remote: Enumerating objects: 62, done.\u001b[K\n",
      "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
      "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
      "remote: Total 62 (delta 29), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (62/62), 2.40 MiB | 676.00 KiB/s, done.\n",
      "Resolving deltas: 100% (29/29), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sam-paech/antislop-sampler.git\n",
    "!mv antislop-sampler antislop_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from antislop_sampler.antislop_generate import generate_antislop, chat_antislop\n",
    "\n",
    "# Enable efficient transfer for Hugging Face models\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = \"1\"\n",
    "\n",
    "# Set the device to 'cuda' if available, else 'cpu'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify the model name (replace with your preferred model)\n",
    "model_name = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "#model.pad_token_id = tokenizer.eos_token_id\n",
    "model.to(device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if os.path.exists('antislop_sampler/slop_phrase_prob_adjustments.json'):\n",
    "    with open('antislop_sampler/slop_phrase_prob_adjustments.json', 'r') as f:\n",
    "        slop_phrase_prob_adjustments = dict(json.load(f)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a story about Elara, the weaver of tapestries in future Technopolis. In the bustling city, a group of \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sam/.local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In the year 2178, in the sprawling city of New Elyria, the art of weaving tapestries had reached its peak. In a small, yet cozy shop tucked away in a quiet alley, a lone weaver named Elian worked day and night to create some of the most exquisite and sought-after pieces in the city. Her name was whispered among the locals as the Weaver of Dreams, a master weaver with a deep connection to the threads of fate and the fabric of reality.\n",
      "\n",
      "Elian's shop, \"Threads of Elyria,\" was a haven for those seeking tales of the past, present, and future. The walls were adorned with an array of woven tapestries, each one telling a different story, woven with care and precision by Elian's skilled hands. People from all corners of the city would come to visit her, hoping to unravel the mysteries hidden within the threads.\n",
      "\n",
      "Among them was a young apprentice named Lyra, who had heard tales of the Weaver of Dreams from her mother. Lyra was a curious and ambitious young woman, with a passion for storytelling and a thirst for knowledge. She had always dreamed of one day becoming a master weaver herself, but her father, a renowned historian, had discouraged her from pursuing a life of weaving, fearing it would be a mundane occupation.\n",
      "\n",
      "One day, Lyra's father fell ill, and as he lay on his deathbed, he handed her a small, intricately woven thread. It was a fragment of a long-forgotten tale, one that told of a hidden world beyond the city, where magic and technology merged in ways both wondrous and terrifying. The thread"
     ]
    }
   ],
   "source": [
    "# Chat generation with streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "for token in chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_length=400,\n",
    "    # Antislop sampling may be less reliable at low temperatures.\n",
    "    temperature=1,    \n",
    "    min_p=0.1,\n",
    "    # The adjustment_strength param scales how strongly the probability adjustments are applied.\n",
    "    # A value of 1 means the values in slop_phrase_prob_adjustments (or the defaults) are used unmodified.\n",
    "    # Reasonable values are 0 (disabled) thru 10+ (effectively banning the list).\n",
    "    adjustment_strength=10.0,\n",
    "    # Optional: Provide a list of slop phrases and probability adjustments\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    streaming=True\n",
    "):\n",
    "    print(tokenizer.decode(token), end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "In the heart of Future Polis, where the sun dipped into the horizon and painted the sky with hues of crimson and gold, a young weaver named Elian stood at the edge of the city's central square. The air was alive with the hum of hoverbikes and the chatter of pedestrians, the smells of street food and machinery wafting through the air.\n",
      "\n",
      "For as long as anyone could remember, the people of Polis had relied on Elian's skills as a weaver to create the city's iconic tapestries. Her hands moved deftly, the threads of silver and gold dancing across her loom as she wove tales of the city's history and mythologies. Her fingers moved with the speed and precision of a surgeon, each stitch a tiny piece of Polis's rich cultural heritage.\n",
      "\n",
      "Elian's latest commission was a grand one – a massive mural depicting the founding of the city, the great hero, Arin the Unyielding, and his brave warriors. It would be a masterpiece, a celebration of Polis's triumph and the triumphs of its people.\n",
      "\n",
      "As she worked, Elian's mind wandered to the people of the city's lower districts, who struggled to make ends meet. The city was a melting pot of cultures, a place where the old and the new blended together in a swirling dance of innovation and tradition. But beneath the surface, tensions simmered – tensions between the haves and the have-nots, between those who had and those who had not.\n",
      "\n",
      "One night, as Elian worked late into the night, a young apprentice, Kael, crept into the square, his eyes scanning the\n"
     ]
    }
   ],
   "source": [
    "# Chat generation without streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "generated_text = chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_length=400,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=2.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    streaming=False\n",
    ")\n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " urchins and street children stumble upon her loom, and they discover that her tapestries are not just beautiful works of art, but also hold a powerful secret.\n",
      "As the urchins explore the city's hidden corners, they notice that the tapestries seem to be changing, subtly shifting and rearranging themselves. At first, they think it's just a trick of the light, but as they watch, the tapestries begin to tell a story of their own – a tale of love, loss, and the struggles of growing up.\n",
      "\n",
      "The urchins, led by a curious and adventurous young girl named Aria, become obsessed with unraveling the mystery of the tapestries. They spend their days scouring the city for more clues, and their nights exploring the hidden alleys and courtyards, searching for any sign of the mysterious weaver.\n",
      "\n",
      "As they delve deeper into the city, they begin to notice that the tapestries are not just telling stories, but also revealing hidden truths about the city's inhabitants. They see glimpses of people's pasts, their fears, and their dreams. The tapestries seem to be a window into the city's soul, and the urchins are determined to learn more.\n",
      "\n",
      "One night, as they gather around a fire in a hidden courtyard, they discover a\n"
     ]
    }
   ],
   "source": [
    "# generate without streaming\n",
    "generated_text = generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=2.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    streaming=False\n",
    ")        \n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12 of the most skilled artisans work together to create the grand tapestries that adorn the walls of the city's central square.\n",
      "\n",
      "The city of Newhaven is a marvel of innovation and progress, where technology and magic coexist in a symbiotic relationship. The air is alive with the hum of machines, and the streets are paved with a glittering substance called Glimmerstone, which is harvested from the crystals that line the city's skyscrapers. The Glimmerstone is used to power the city's infrastructure, and it's also a key component in the creation of the city's famous tapestries.\n",
      "\n",
      "In the heart of Newhaven's central square, a group of 12 artisans gather to work on their most ambitious project yet: the \"Elysian Mural\". This massive wall of tapestries will be the centerpiece of the square, and it will be the pride of the city. Each artisan has been selected for their unique skills and expertise, and they come from different walks of life.\n",
      "\n",
      "There's Arin, the master weaver from the ancient district of Luminaria, who has spent years perfecting his craft. He's known for his breathtaking patterns and colors, which seem to shift and change depending on the light. Next to him sits Lyra, the skilled weaver from the sprawling district of Nex"
     ]
    }
   ],
   "source": [
    "# generate with streaming\n",
    "for token in generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    adjustment_strength=2.0,\n",
    "    streaming=True\n",
    "):\n",
    "    print(tokenizer.decode(token), end='', flush=True)"
   ]
  },
      {
      "cell_type": "code",
      "source": [
        "import time\n",
        "print(f\"\\nExecution time with use_cache=False (1B model & max_length=300):\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for token in generate_antislop(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    prompt=prompt,\n",
        "    max_length=300,\n",
        "    temperature=0.01,\n",
        "    min_p=0.1,\n",
        "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
        "    adjustment_strength=12.0,\n",
        "    streaming=True,\n",
        "    use_cache=False\n",
        "):\n",
        "    print(tokenizer.decode(token), end='', flush=True)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "execution_time_use_cache_false = end_time - start_time\n",
        "\n",
        "###\n",
        "print(f\"\\nExecution time with use_cache=True (1B model & max_length=300):\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for token in generate_antislop(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    prompt=prompt,\n",
        "    max_length=300,\n",
        "    temperature=0.01,\n",
        "    min_p=0.1,\n",
        "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
        "    adjustment_strength=12.0,\n",
        "    streaming=True,\n",
        "    use_cache=True\n",
        "):\n",
        "    print(tokenizer.decode(token), end='', flush=True)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "execution_time_use_cache_true = end_time - start_time\n",
        "\n",
        "print(f\"\\nExecution time with use_cache=False (1B model & max_length=300): {execution_time_use_cache_false} seconds\")\n",
        "print(f\"Execution time with use_cache=True (1B model & max_length=300): {execution_time_use_cache_true} seconds\")"
      ],
      "metadata": {},
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Execution time with use_cache=False (1B model & max_length=300):\n",
            " urchins have taken over the city's central square, causing chaos and destruction. The city's elite, led by the cunning and ruthless Lord Arin, have dispatched a team of elite guards to quell the uprising.\n",
            "\n",
            "As the guards approach the central square, they are met with a sight that is both familiar and yet, utterly alien. The urchins, with their makeshift armor and crude but effective tools, are holding the city's elite at bay. The guards, clad in their fine armor and carrying their deadly swords, are at a loss for how to deal with the situation.\n",
            "\n",
            "Meanwhile, in the shadows, a young weaver named Zephyr watches the scene unfold. Zephyr is a skilled weaver, but not just any weaver. She is a weaver of the ancient art, one who has spent years studying the secrets of the tapestries that once adorned the walls of the city's great halls. Zephyr's tapestries are said to hold the memories of the city's past, and she is determined to use her knowledge to help bring peace to the city.\n",
            "\n",
            "As the guards close in, Zephyr sees her chance. She begins to weave a new pattern, one that will weave together the\n",
            "Execution time with use_cache=True (1B model & max_length=300):\n",
            " urchins have taken over the city's central square, causing chaos and destruction. The city's elite, led by the cunning and ruthless Lord Arin, have dispatched a team of skilled warriors to quell the uprising.\n",
            "\n",
            "As the city's elite approach, a young weaver named Althaea, who has been watching the chaos unfold from a distance, decides to intervene. She sees an opportunity to use her skills to help the urchins and bring about a new era of cooperation and prosperity in the city.\n",
            "\n",
            "Althaea approaches the urchins, who are armed and ready for battle, and begins to weave a new pattern into the city's central square. The pattern is a symbol of unity and cooperation, and as she works, the urchins begin to see the potential for a new future.\n",
            "\n",
            "The city's elite, led by Lord Arin, arrive on the scene, and a fierce battle ensues. Althaea's weaving becomes a focal point of the conflict, as the warriors clash with the urchins. But as the battle rages on, Althaea's weaving begins to take on a life of its own, weaving together the threads of the city's history, past and present.\n",
            "\n",
            "The warriors, caught\n",
            "Execution time with use_cache=False (1B model & max_length=300): 60.837812662124634 seconds\n",
            "Execution time with use_cache=True (1B model & max_length=300): 8.247310400009155 seconds\n"
          ]
        }
      ]
    }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
